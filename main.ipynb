{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "908e8499",
   "metadata": {},
   "source": [
    "## Francisco Teixeira Rocha Aragão - 2021031726\n",
    "## Lorenzo Carneiro Magalhães - 2021031505\n",
    "\n",
    "### Implementação do problema de Entity Search - Information Retrieval\n",
    "\n",
    "Abaixo estão as implementações para cada submissão realizada. Vale destacar que os caminhos podem variar, então é importante OU colocar os dados na entrada correta OU alterar os caminhos no código.\n",
    "\n",
    "O código está repetido entre cada submissão pois a ideia é que cada uma seja independente testando diferentes elementos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d754d",
   "metadata": {},
   "source": [
    "### Primeira submissão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f9b7f",
   "metadata": {},
   "source": [
    "Essa primeira submissão é bem simples e implementa o método bm25 sobre o corpus de documentos.\n",
    "\n",
    "O indice é gerenciado manualmente, sendo feito o preprocessamento dos documentos, com as informações sobre IDs e tokens sendo salvas internamente para serem utilizadas no ranking.\n",
    "\n",
    "Eessa etapa é muito custosa pois o índice é salvo em memória, porém conseguimos rodar localmente. Em outras máquinas isso possivelmente pode ser ajustado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf296d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "# definindo constantes para normalização dos textos\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "PUNCT = set(string.punctuation)\n",
    "REMOVE_SPACE = re.compile(r\"\\s+\") # regex para substituir múltiplos espaços por um único espaço\n",
    "\n",
    "def normalize(text: str) -> List[str]:\n",
    "     \"\"\"\n",
    "     • lower-case\n",
    "     • tokeniza com wordpunct_tokenize\n",
    "     • remove stop-words / pontuação\n",
    "     • descarta tokens de 1 caractere\n",
    "     \"\"\"\n",
    "     text = REMOVE_SPACE.sub(\" \", text.lower())\n",
    "     tokens = [\n",
    "         t for t in wordpunct_tokenize(text)\n",
    "         if t not in STOPWORDS and t not in PUNCT and len(t) > 1\n",
    "     ]\n",
    "     return tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef63bf2",
   "metadata": {},
   "source": [
    "Aqui o corpus é percorrido para gerar o indice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# definindo constantes e caminhos para arquivos\n",
    "DATA_DIR     = Path(\"data/ir-20251-rc\")\n",
    "CORPUS_PATH  = DATA_DIR / \"corpus.jsonl\"\n",
    "TEST_PATH    = DATA_DIR / \"test_queries.csv\"\n",
    "SUBM_PATH    = Path(\"submission.csv\")\n",
    "TOP_K        = 100  # máx. de entidades por query como descrito no enunciado\n",
    "\n",
    "\n",
    "# salvando estruturas de indice pra armazenar informações do corpus\n",
    "docs_tokens: List[List[str]] = []\n",
    "entity_ids: List[str]        = []\n",
    "\n",
    "with CORPUS_PATH.open(encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f, desc=\"corpus.jsonl\"):\n",
    "        doc = json.loads(line)\n",
    "\n",
    "        # concatena campos relevantes de cada documento no corpus\n",
    "        combined = \" \".join([\n",
    "            doc.get(\"title\", \"\"),\n",
    "            doc.get(\"text\",  \"\"),\n",
    "            \" \".join(doc.get(\"keywords\", [])),\n",
    "        ])\n",
    "\n",
    "        docs_tokens.append(normalize(combined))\n",
    "        entity_ids.append(doc[\"id\"])\n",
    "\n",
    "bm25 = BM25Okapi(docs_tokens)\n",
    "print(f\"Num : {len(entity_ids):,} documentos indexados.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94e144",
   "metadata": {},
   "source": [
    "Por fim as queries são processadas utilizando o bm25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"ranking BM25\")\n",
    "rows_out: List[List[str]] = []\n",
    "\n",
    "# pegando os scores de cada query e salvando os resultados\n",
    "with TEST_PATH.open(encoding=\"utf-8\") as f:\n",
    "    \n",
    "    reader = csv.DictReader(f)\n",
    "    \n",
    "    for row in tqdm(reader, desc=\"test_queries.csv\"):\n",
    "        \n",
    "        qid, query = row[\"QueryId\"], row[\"Query\"]\n",
    "        \n",
    "        q_tokens   = normalize(query)\n",
    "\n",
    "        scores   = bm25.get_scores(q_tokens)\n",
    "        best_idx = sorted(range(len(scores)),\n",
    "                          key=scores.__getitem__, reverse=True)[:TOP_K]\n",
    "        \n",
    "        rows_out.extend([[qid, entity_ids[i]] for i in best_idx])\n",
    "\n",
    "print(f\"total  de linhas na saída: {len(rows_out):,}\\n\")\n",
    "\n",
    "\n",
    "# escrevendo arquivo de saida com os resultados\n",
    "with SUBM_PATH.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    writer.writerow([\"QueryId\", \"EntityId\"])\n",
    "    writer.writerows(rows_out)\n",
    "\n",
    "print(f\"fim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980087d0",
   "metadata": {},
   "source": [
    "### Segunda submissão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aa47fd",
   "metadata": {},
   "source": [
    "Essa submissão é mais robusta do que a primeira, pois além do bm25, são utilizadas outras estratégias como expansão de queries além do  modelo CrossEncoder para realizar o reranking.\n",
    "\n",
    "O gerenciamento do indice é feito pela biblioteca `pyserini`, o que não é controlado manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13830d",
   "metadata": {},
   "source": [
    "Aqui apenas estou organizando os parametros iniciais e formatando o corpus para o formato adequado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad9c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv, json, tqdm, numpy as np\n",
    "from pathlib import Path\n",
    "#from pyserini.search import SimpleSearcher # essa versão está deprecada, porém funciona também\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# caminhos aos arquivos importantes\n",
    "DATA      = Path(\"data/ir-20251-rc\")\n",
    "TEST_FILE = DATA / \"test_queries.csv\"\n",
    "SUBM_FILE = Path(\"submission.csv\")\n",
    "INDEX_DIR = Path(\"index_entities\")\n",
    "\n",
    "\n",
    "# trabalhando com formatação do corpus para Anserini\n",
    "path_in  = DATA/ \"corpus.jsonl\"\n",
    "\n",
    "os.makedirs(\"corp_anserini\", exist_ok=True)\n",
    "path_out = Path(\"corp_anserini\", \"corpus.jsonl\")\n",
    "\n",
    "\n",
    "with path_in.open(encoding=\"utf-8\") as fin, \\\n",
    "     path_out.open(\"w\", encoding=\"utf-8\") as fout:\n",
    "    for line in tqdm.tqdm(fin, desc=\"convert\"):\n",
    "        obj = json.loads(line)\n",
    "        contents = \" \".join([\n",
    "            obj.get(\"title\",\"\"),\n",
    "            \" \".join(obj.get(\"keywords\", [])),\n",
    "            obj.get(\"text\",\"\")\n",
    "        ])\n",
    "        fout.write(json.dumps({\"id\": obj[\"id\"], \"contents\": contents}) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a066b5b",
   "metadata": {},
   "source": [
    "Com a biblioteca `pyserini`, o corpus é então indexado e salvo em um diretório especifico. A biblioteca cuida de todo o processo, não sendo feito nada manualmente.\n",
    "Não encontramos API para isso então o comando é feito diretamente via subprocess.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# essa variavel de ambiente evita que o java use muita memoria\n",
    "# instalei o java com : sudo apt install openjdk-17-sdk\n",
    "os.environ['_JAVA_OPTIONS'] = '-Xms4g -Xmx24g'\n",
    "\n",
    "# só passo os parametros necessarios e os caminhos para os arquivos\n",
    "# o numero de threads pode ser ajustado\n",
    "cmd = [\n",
    "    'python', '-m', 'pyserini.index.lucene',\n",
    "    '-collection', 'JsonCollection',\n",
    "    '-generator', 'DefaultLuceneDocumentGenerator',\n",
    "    '-input', './corp_anserini',\n",
    "    '-index', 'index_entities',\n",
    "    '-threads', '4',\n",
    "    '-storePositions', '-storeDocvectors', '-storeRaw'\n",
    "]\n",
    "\n",
    "subprocess.run(cmd, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c60f38",
   "metadata": {},
   "source": [
    "Agora rodo o todo o novo pipeline de ranking:\n",
    "\n",
    "Bm25 + rm3 (ranking inicial) -> CrossEncoder (atua sobre ranking inicial de documentos) -> Ranking final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parametros do pipeline de ranking\n",
    "CAND_K = 1000   # numero de candidatos que recupero inicialmente\n",
    "FINAL_K= 100    # numero final de entidades\n",
    "W_CE = 0.7    # peso do cross-encoder na interpolação com o bm25\n",
    "\n",
    "# agora sim inicio das tarefas de ranqueamento\n",
    "searcher = LuceneSearcher(str(INDEX_DIR))\n",
    "searcher.set_bm25(k1=0.92, b=0.36) # parametros do bm25, k1 controla a sensibilidade ao tamanho do documento, b controla a normalização\n",
    "searcher.set_rm3(fb_terms=10, fb_docs=50, original_query_weight=0.5) # parâmetros do RM3, fb_terms é o número de termos de feedback, fb_docs é o número de documentos de feedback, original_query_weight é o peso da query original\n",
    "\n",
    "ce = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    "\n",
    "# como vou fazer interpolação dos modelos, preciso normalizar os scores dos metodos para poder agregalos\n",
    "def normalize_scores(d):\n",
    "    vals = np.array(list(d.values()))\n",
    "    return {k: (v - vals.min()) / (np.ptp(vals) + 1e-9) for k, v in d.items()}\n",
    "\n",
    "rows_out = []\n",
    "\n",
    "with TEST_FILE.open() as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in tqdm.tqdm(reader, desc=\"Queries\"):\n",
    "        qid, query = row[\"QueryId\"], row[\"Query\"]\n",
    "\n",
    "        # inicialmente uso rm3 + bm25 para achar candidatos relevantes para a query\n",
    "        hits = searcher.search(query, CAND_K)\n",
    "        cand_ids  = [h.docid for h in hits]\n",
    "        bm25_dict = {h.docid: h.score for h in hits}\n",
    "\n",
    "        # agora que tenho os candidatos, uso o cross-encoder para re-ranquear esses candidatos\n",
    "        texts = [searcher.doc(did).raw() for did in cand_ids]\n",
    "        ce_scores = ce.predict([(query, t) for t in texts], batch_size=32)\n",
    "        ce_dict = dict(zip(cand_ids, ce_scores))\n",
    "\n",
    "        # jutno os scores com interpolação\n",
    "        b_norm = normalize_scores(bm25_dict)\n",
    "        c_norm = normalize_scores(ce_dict)\n",
    "        final_scores = {d: W_CE*c_norm[d] + (1-W_CE)*b_norm[d] for d in cand_ids}\n",
    "\n",
    "        top_ids = sorted(final_scores, key=final_scores.get, reverse=True)[:FINAL_K]\n",
    "        rows_out.extend([[qid, did] for did in top_ids])\n",
    "\n",
    "# salvo os resultados obtidos \n",
    "with SUBM_FILE.open(\"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"QueryId\", \"EntityId\"])\n",
    "    writer.writerows(rows_out)\n",
    "\n",
    "print(\"fim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df1f0cf",
   "metadata": {},
   "source": [
    "## Terceira submissão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a766ed3",
   "metadata": {},
   "source": [
    "Organizando imports e definindo função de preprocessamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512396a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv, json, tqdm, numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "#from pyserini.search import SimpleSearcher\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from sentence_transformers import CrossEncoder\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# definindo constantes para normalização dos textos\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "PUNCT = set(string.punctuation)\n",
    "REMOVE_SPACE = re.compile(r\"\\s+\") # regex para substituir múltiplos espaços por um único espaço\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "     \"\"\"\n",
    "     • lower-case\n",
    "     • tokeniza com wordpunct_tokenize\n",
    "     • remove stop-words / pontuação\n",
    "     • descarta tokens de 1 caractere\n",
    "     \"\"\"\n",
    "     text = REMOVE_SPACE.sub(\" \", text.lower())\n",
    "     tokens = [\n",
    "         t for t in wordpunct_tokenize(text)\n",
    "         if t not in STOPWORDS and t not in PUNCT and len(t) > 1\n",
    "     ]\n",
    "     return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7696d9d",
   "metadata": {},
   "source": [
    "Aqui apenas estou organizando os parametros iniciais e formatando o corpus para o formato adequado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9001469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# caminhos aos arquivos importantes\n",
    "DATA      = Path(\"data/ir-20251-rc\")\n",
    "TEST_FILE = DATA / \"test_queries.csv\"\n",
    "SUBM_FILE = Path(\"submission.csv\")\n",
    "INDEX_DIR = Path(\"index_entities\")\n",
    "\n",
    "# trabalhando com formatação do corpus para Anserini\n",
    "path_in  = DATA/ \"corpus.jsonl\"\n",
    "\n",
    "os.makedirs(\"corp_anserini\", exist_ok=True)\n",
    "path_out = Path(\"corp_anserini\", \"corpus.jsonl\")\n",
    "\n",
    "with path_in.open(encoding=\"utf-8\") as fin, \\\n",
    "     path_out.open(\"w\", encoding=\"utf-8\") as fout:\n",
    "    for line in tqdm.tqdm(fin, desc=\"convert\"):\n",
    "        obj = json.loads(line)\n",
    "        contents = \" \".join([\n",
    "            obj.get(\"title\",\"\"),\n",
    "            \" \".join(obj.get(\"keywords\", [])),\n",
    "            obj.get(\"text\",\"\")\n",
    "        ])\n",
    "        fout.write(json.dumps({\"id\": obj[\"id\"], \"contents\": normalize(contents)}) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ad81ee",
   "metadata": {},
   "source": [
    "Com a biblioteca `pyserini`, o corpus é então indexado e salvo em um diretório especifico. A biblioteca cuida de todo o processo, não sendo feito nada manualmente.\n",
    "Não encontramos API para isso então o comando é feito diretamente via subprocess.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f09b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# essa variavel de ambiente evita que o java use muita memoria\n",
    "# instalei o java com : sudo apt install openjdk-17-sdk\n",
    "os.environ['_JAVA_OPTIONS'] = '-Xms4g -Xmx24g'\n",
    "\n",
    "# só passo os parametros necessarios e os caminhos para os arquivos\n",
    "# o numero de threads pode ser ajustado\n",
    "cmd = [\n",
    "    'python', '-m', 'pyserini.index.lucene',\n",
    "    '-collection', 'JsonCollection',\n",
    "    '-generator', 'DefaultLuceneDocumentGenerator',\n",
    "    '-input', './corp_anserini',\n",
    "    '-index', 'index_entities',\n",
    "    '-threads', '4', \n",
    "    '-storePositions', '-storeDocvectors', '-storeRaw'\n",
    "]\n",
    "\n",
    "subprocess.run(cmd, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7516e432",
   "metadata": {},
   "source": [
    "A ideia agora foi alterar alguns parametros, como o numero de documentos retornados pelo bm25 (que será usado no cross encoder). Também foi alterado o peso da interpolação e os parametros do Bm25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0810c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros do pipeline de ranking\n",
    "CAND_K = 500   # numero de candidatos que recupero inicialmente\n",
    "FINAL_K= 100    # numero final de entidades\n",
    "W_CE = 0.8    # peso do cross-encoder na interpolação com o bm25\n",
    "\n",
    "# agora sim inicio das tarefas de ranqueamento\n",
    "searcher = LuceneSearcher(str(INDEX_DIR))\n",
    "searcher.set_bm25(k1=1.2, b=0.75) # parametros do bm25, k1 controla a sensibilidade ao tamanho do documento, b controla a normalização\n",
    "searcher.set_rm3(fb_terms=10, fb_docs=50, original_query_weight=0.6) # parâmetros do RM3, fb_terms é o número de termos de feedback, fb_docs é o número de documentos de feedback, original_query_weight é o peso da query original\n",
    "\n",
    "ce = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    "\n",
    "# como vou fazer interpolação dos modelos, preciso normalizar os scores dos metodos para poder agregalos\n",
    "def normalize_scores(d):\n",
    "    vals = np.array(list(d.values()))\n",
    "    return {k: (v - vals.min()) / (np.ptp(vals) + 1e-9) for k, v in d.items()}\n",
    "\n",
    "rows_out = []\n",
    "\n",
    "with TEST_FILE.open() as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in tqdm.tqdm(reader, desc=\"Queries\"):\n",
    "        qid, query = row[\"QueryId\"], row[\"Query\"]\n",
    "\n",
    "        # inicialmente uso rm3 + bm25 para achar candidatos relevantes para a query\n",
    "        hits = searcher.search(query, CAND_K)\n",
    "        cand_ids  = [h.docid for h in hits]\n",
    "        bm25_dict = {h.docid: h.score for h in hits}\n",
    "\n",
    "        # agora que tenho os candidatos, uso o cross-encoder para re-ranquear esses candidatos\n",
    "        texts = [searcher.doc(did).raw() for did in cand_ids]\n",
    "        ce_scores = ce.predict([(query, t) for t in texts], batch_size=32)\n",
    "        ce_dict = dict(zip(cand_ids, ce_scores))\n",
    "\n",
    "        # jutno os scores com interpolação\n",
    "        b_norm = normalize_scores(bm25_dict)\n",
    "        c_norm = normalize_scores(ce_dict)\n",
    "        final_scores = {d: W_CE*c_norm[d] + (1-W_CE)*b_norm[d] for d in cand_ids}\n",
    "\n",
    "        top_ids = sorted(final_scores, key=final_scores.get, reverse=True)[:FINAL_K]\n",
    "        rows_out.extend([[qid, did] for did in top_ids])\n",
    "\n",
    "# salvo os resultados obtidos \n",
    "with SUBM_FILE.open(\"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"QueryId\", \"EntityId\"])\n",
    "    writer.writerows(rows_out)\n",
    "\n",
    "print(\"fim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1704a3",
   "metadata": {},
   "source": [
    "### Quarta submissão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a6399",
   "metadata": {},
   "source": [
    "Como essa submissão apenas altera os scores finais, não há a necessidade de trabalhar com o corpus novamente igual nas últimas etapas, então essa parte foi ignorada.\n",
    "\n",
    "Assim, agora essa submissão apenas usa o score final totalmente dependente do modelo de cross encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb1bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros do pipeline de ranking\n",
    "CAND_K = 1000   # numero de candidatos que recupero inicialmente\n",
    "FINAL_K= 100    # numero final de entidades\n",
    "\n",
    "# agora sim inicio das tarefas de ranqueamento\n",
    "searcher = LuceneSearcher(str(INDEX_DIR))\n",
    "searcher.set_bm25(k1=1.2, b=0.75) # parametros do bm25, k1 controla a sensibilidade ao tamanho do documento, b controla a normalização\n",
    "searcher.set_rm3(fb_terms=12, fb_docs=50, original_query_weight=0.6) # parâmetros do RM3, fb_terms é o número de termos de feedback, fb_docs é o número de documentos de feedback, original_query_weight é o peso da query original\n",
    "\n",
    "ce = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    "\n",
    "\n",
    "rows_out = []\n",
    "\n",
    "with TEST_FILE.open() as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in tqdm.tqdm(reader, desc=\"Queries\"):\n",
    "        qid, query = row[\"QueryId\"], row[\"Query\"]\n",
    "\n",
    "        # inicialmente uso rm3 + bm25 para achar candidatos relevantes para a query\n",
    "        hits = searcher.search(query, CAND_K)\n",
    "        cand_ids  = [h.docid for h in hits]\n",
    "\n",
    "        # agora que tenho os candidatos, uso o cross-encoder para re-ranquear esses candidatos\n",
    "        texts = [searcher.doc(did).raw() for did in cand_ids]\n",
    "        ce_scores = ce.predict([(query, t) for t in texts], batch_size=32)\n",
    "        ce_dict = dict(zip(cand_ids, ce_scores))\n",
    "\n",
    "        # agora só uso os scores do cross-encoder\n",
    "\n",
    "        final_scores = {d: ce_dict[d] for d in cand_ids}\n",
    "\n",
    "        top_ids = sorted(final_scores, key=final_scores.get, reverse=True)[:FINAL_K]\n",
    "        rows_out.extend([[qid, did] for did in top_ids])\n",
    "\n",
    "# salvo os resultados obtidos \n",
    "with SUBM_FILE.open(\"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"QueryId\", \"EntityId\"])\n",
    "    writer.writerows(rows_out)\n",
    "\n",
    "print(\"fim\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
